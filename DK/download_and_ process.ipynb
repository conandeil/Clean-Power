{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The parameters for loading source files must be set once in the \"def main ()\" function, see lines 77-79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Coordinates DK_wind  584\n",
      "Missing Coordinates DK_solar  1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import posixpath\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import re\n",
    "import zipfile\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utm  # for transforming geoinformation in the utm format\n",
    "import requests\n",
    "from string import Template\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%d %b %Y %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "fof = os.path.realpath(__name__)\n",
    "path = os.path.split(fof)[0][:-2]\n",
    "\n",
    "# Get column translation list\n",
    "columnnames = pd.read_csv(os.path.join('input', path + 'service\\\\' + 'column_translation_list.csv'))\n",
    "columnnames.head(2)\n",
    "\n",
    "# Get value translation list\n",
    "valuenames = pd.read_csv(os.path.join('input', path + 'service\\\\' + 'value_translation_list.csv'))\n",
    "valuenames.head(2)\n",
    "\n",
    "\n",
    "def download_and_cache(url, session=None):\n",
    "    \"\"\"This function downloads a file into a folder called \n",
    "    original_data and returns the local filepath.\"\"\"\n",
    "    path = urllib.parse.urlsplit(url).path\n",
    "    filename = posixpath.basename(path)\n",
    "    filepath = os.path.join('input', 'original_data', filename)\n",
    "\n",
    "    # check if file exists, if not download it\n",
    "    if not os.path.exists(filepath):\n",
    "        if not session:\n",
    "            print('No session')\n",
    "            session = requests.session()\n",
    "\n",
    "        r = session.get(url, stream=True)\n",
    "\n",
    "        chuncksize = 1024\n",
    "        with open(filepath, 'wb') as file:\n",
    "            for chunck in r.iter_content(chuncksize):\n",
    "                file.write(chunck)\n",
    "    filepath = '' + filepath\n",
    "    return filepath\n",
    "\n",
    "def check_file_existence(url):\n",
    "    hh = url.split('/')[-1]\n",
    "    ff = './input/' + hh\n",
    "    try:\n",
    "        file = open(ff)\n",
    "        file.close()\n",
    "        link = url.split('/')[-1]\n",
    "    except:\n",
    "        r = requests.get(url).status_code\n",
    "        if r != 200: print('Invalid file path: ' + '\"' + url + '\"')\n",
    "        return\n",
    "        link = url\n",
    "    return link\n",
    "\n",
    "def main():\n",
    "    # Here you need to specify the path with the location of the files on the Internet\n",
    "\n",
    "        DK_ens = 'https://ens.dk/sites/ens.dk/files/Vindenergi/anlaegprodtilnettet.xls'\n",
    "        DK_energinet = 'https://www.energinet.dk/-/media/Energinet/El-CSI/Dokumenter/Data/SolcellerGraf-2016-11.xlsx'\n",
    "        DK_geo = 'http://download.geonames.org/export/zip/DK.zip'\n",
    "\n",
    "        url_DK_ens =  check_file_existence(DK_ens)\n",
    "        url_DK_energinet = check_file_existence(DK_energinet)\n",
    "        url_DK_geo = check_file_existence(DK_geo)\n",
    "           \n",
    "        \n",
    "        # Get wind turbines data\n",
    "        DK_wind_df = pd.read_excel('./input/' + url_DK_ens,\n",
    "                                   sheet_name='IkkeAfmeldte-Existing turbines',\n",
    "                                   thousands='.',\n",
    "                                   header=17,\n",
    "                                   skipfooter=3,\n",
    "                                   usecols=16,\n",
    "                                   converters={'Møllenummer (GSRN)': str,\n",
    "                                               'Kommune-nr': str,\n",
    "                                               'Postnr': str}\n",
    "                                   )\n",
    "\n",
    "        # Get photovoltaic data\n",
    "        DK_solar_df = pd.read_excel('./input/' + url_DK_energinet,                            \n",
    "                                    sheet_name='Data',\n",
    "                                    converters={'Postnr': str}\n",
    "                                    )\n",
    "\n",
    "        # Choose the translation terms for Denmark, create dictionary and show dictionary\n",
    "        idx_DK = columnnames[columnnames['country'] == 'DK'].index\n",
    "        column_dict_DK = columnnames.loc[idx_DK].set_index('original_name')['opsd_name'].to_dict()\n",
    "\n",
    "        # Windows has problems reading the csv entry for east and north (DK).\n",
    "        # The reason might be the difference when opening the csv between linux and\n",
    "        # windows.\n",
    "        column_dict_DK_temp = {}\n",
    "        for k, v in column_dict_DK.items():\n",
    "            column_dict_DK_temp[k] = v\n",
    "            if v == 'utm_east' or v == 'utm_north':\n",
    "                # merge 2 lines to 1\n",
    "                new_key = ''.join(k.splitlines())\n",
    "                column_dict_DK_temp[new_key] = v\n",
    "\n",
    "        column_dict_DK = column_dict_DK_temp\n",
    "\n",
    "        column_dict_DK\n",
    "\n",
    "        # Translate columns by list\n",
    "        DK_wind_df['X (øst) koordinat UTM 32 Euref89'] = DK_wind_df['X (øst) koordinat \\nUTM 32 Euref89']\n",
    "        DK_wind_df['Y (nord) koordinat UTM 32 Euref89'] = DK_wind_df['Y (nord) koordinat \\nUTM 32 Euref89']\n",
    "\n",
    "        #and 13 are the keys that make problems\n",
    "        DK_wind_df.drop(DK_wind_df.columns[[12, 13]], axis=1, inplace=True)\n",
    "\n",
    "        # Replace column names based on column_dict_DK\n",
    "        DK_wind_df.rename(columns=column_dict_DK, inplace=True)\n",
    "        DK_solar_df.rename(columns=column_dict_DK, inplace=True)\n",
    "\n",
    "        # Add names of the data sources to the DataFrames\n",
    "        DK_wind_df['data_source'] = 'Energistyrelsen'\n",
    "        DK_solar_df['data_source'] = 'Energinet.dk'\n",
    "\n",
    "        # Add energy source level 2 and technology for each of the two DataFrames\n",
    "        DK_wind_df['energy_source_level_2'] = 'Wind'\n",
    "        DK_solar_df['energy_source_level_2'] = 'Solar'\n",
    "        DK_solar_df['technology'] = 'Photovoltaics'\n",
    "\n",
    "        # Choose the translation terms for Denmark, create dictionary and show dictionary\n",
    "        idx_DK = valuenames[valuenames['country'] == 'DK'].index\n",
    "        value_dict_DK = valuenames.loc[idx_DK].set_index('original_name')['opsd_name'].to_dict()\n",
    "        value_dict_DK\n",
    "\n",
    "        # Replace all original value names by the OPSD value names\n",
    "        DK_wind_df.replace(value_dict_DK, inplace=True)\n",
    "\n",
    "        # Index for all values with utm information\n",
    "        idx_notnull = DK_wind_df['utm_east'].notnull()\n",
    "\n",
    "        # Convert from UTM values to latitude and longitude coordinates\n",
    "        DK_wind_df['lonlat'] = DK_wind_df.loc[idx_notnull, ['utm_east', 'utm_north']\n",
    "                                              ].apply(lambda x: utm.to_latlon(x[0],\n",
    "                                                                              x[1],\n",
    "                                                                              32,\n",
    "                                                                              'U'), axis=1).astype(str)\n",
    "\n",
    "        # Split latitude and longitude in two columns\n",
    "        lat = []\n",
    "        lon = []\n",
    "\n",
    "        for row in DK_wind_df['lonlat']:\n",
    "            try:\n",
    "                # Split tuple format\n",
    "                # into the column lat and lon\n",
    "                row = row.lstrip('(').rstrip(')')\n",
    "                lat.append(row.split(',')[0])\n",
    "                lon.append(row.split(',')[1])\n",
    "            except:\n",
    "                # set NAN\n",
    "                lat.append(np.NaN)\n",
    "                lon.append(np.NaN)\n",
    "\n",
    "        DK_wind_df['lat'] = pd.to_numeric(lat)\n",
    "        DK_wind_df['lon'] = pd.to_numeric(lon)\n",
    "\n",
    "        # drop lonlat column that contains both, latitute and longitude\n",
    "        DK_wind_df.drop('lonlat', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        # Get geo-information\n",
    "        zip_DK_geo = zipfile.ZipFile('./input/' + url_DK_geo)\n",
    "\n",
    "        # Read generated postcode/location file\n",
    "        DK_geo = pd.read_csv(zip_DK_geo.open('DK.txt'), sep='\\t', header=-1)\n",
    "\n",
    "        # add column names as defined in associated readme file\n",
    "        DK_geo.columns = ['country_code', 'postcode', 'place_name', 'admin_name1',\n",
    "                          'admin_code1', 'admin_name2', 'admin_code2', 'admin_name3',\n",
    "                          'admin_code3', 'lat', 'lon', 'accuracy']\n",
    "\n",
    "        # Drop rows of possible duplicate postal_code\n",
    "        DK_geo.drop_duplicates('postcode', keep='last', inplace=True)\n",
    "        DK_geo['postcode'] = DK_geo['postcode'].astype(str)\n",
    "\n",
    "        # Add longitude/latitude infomation assigned by postcode (for Energinet.dk data)\n",
    "        DK_solar_df = DK_solar_df.merge(DK_geo[['postcode', 'lon', 'lat']],\n",
    "                                        on=['postcode'],\n",
    "                                        how='left')\n",
    "\n",
    "        # Show number of units with missing coordinates seperated by wind and solar\n",
    "        print('Missing Coordinates DK_wind ', DK_wind_df.lat.isnull().sum())\n",
    "        print('Missing Coordinates DK_solar ', DK_solar_df.lat.isnull().sum())\n",
    "\n",
    "        # Merge DataFrames for wind and solar into DK_renewables\n",
    "        dataframes = [DK_wind_df, DK_solar_df]\n",
    "        DK_renewables = pd.concat(dataframes)\n",
    "        DK_renewables = DK_renewables.reset_index()\n",
    "\n",
    "        # Assign energy source level 1 to the dataframe\n",
    "        DK_renewables['energy_source_level_1'] = 'Renewable energy'\n",
    "\n",
    "        # Select those columns of the orignal data which are utilised further\n",
    "        column_interest = ['commissioning_date', 'energy_source_level_1', 'energy_source_level_2',\n",
    "                           'technology', 'electrical_capacity_kW', 'dso', 'gsrn_id', 'postcode',\n",
    "                           'municipality_code', 'municipality', 'address', 'address_number',\n",
    "                           'utm_east', 'utm_north', 'lon', 'lat', 'hub_height',\n",
    "                           'rotor_diameter', 'manufacturer', 'model', 'data_source']\n",
    "\n",
    "        # Clean DataFrame from columns other than specified above\n",
    "        DK_renewables = DK_renewables.loc[:, column_interest]\n",
    "        DK_renewables.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # kW to MW\n",
    "        DK_renewables['electrical_capacity_kW'] /= 1000\n",
    "\n",
    "        # adapt column name\n",
    "        DK_renewables.rename(columns={'electrical_capacity_kW': 'electrical_capacity'},\n",
    "                             inplace=True)\n",
    "\n",
    "        DK_renewables.to_pickle('output/DK_renewables.pickle')\n",
    "        DK_renewables.to_csv('output/DK_renewables.csv',sep=';', index=False, encoding='utf-8-sig', mode='w', header=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
